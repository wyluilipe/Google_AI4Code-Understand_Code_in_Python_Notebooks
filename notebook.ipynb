{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/denis/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from translate import Translator\n",
    "translator = Translator(from_lang='russian', to_lang='english')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "                    id                                         cell_order\n0       00001756c60be8  1862f0a6 448eb224 2a9e43d6 7e2f170a 038b763d 7...\n1       00015c83e2717b  2e94bd7a 3e99dee9 b5e286ea da4f7550 c417225b 5...\n2       0001bdd4021779  3fdc37be 073782ca 8ea7263c 80543cd8 38310c80 0...\n3       0001daf4c2c76d  97266564 a898e555 86605076 76cc2642 ef279279 d...\n4       0002115f48f982  9ec225f0 18281c6c e3b6b115 4a044c54 365fe576 a...\n...                ...                                                ...\n139251  fffc30d5a0bc46  09727c0c ff1ea6a0 ddfef603 a01ce9b3 3ba953ee b...\n139252  fffc3b44869198  978a5137 faa48f03 28dfb12a eea2e812 64fef97c 4...\n139253  fffc63ff750064  5015c300 411b85d9 8238198c f4781d1d b5532930 e...\n139254  fffcd063cda949  7e6266ad d8281fc5 d4ffcaef 3e0e4a47 21387fc8 c...\n139255  fffe1d764579d5  1a63248d 9c3b96a5 1398a873 4e2d4c2d f71c538e 8...\n\n[139256 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>cell_order</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00001756c60be8</td>\n      <td>1862f0a6 448eb224 2a9e43d6 7e2f170a 038b763d 7...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00015c83e2717b</td>\n      <td>2e94bd7a 3e99dee9 b5e286ea da4f7550 c417225b 5...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0001bdd4021779</td>\n      <td>3fdc37be 073782ca 8ea7263c 80543cd8 38310c80 0...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0001daf4c2c76d</td>\n      <td>97266564 a898e555 86605076 76cc2642 ef279279 d...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0002115f48f982</td>\n      <td>9ec225f0 18281c6c e3b6b115 4a044c54 365fe576 a...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>139251</th>\n      <td>fffc30d5a0bc46</td>\n      <td>09727c0c ff1ea6a0 ddfef603 a01ce9b3 3ba953ee b...</td>\n    </tr>\n    <tr>\n      <th>139252</th>\n      <td>fffc3b44869198</td>\n      <td>978a5137 faa48f03 28dfb12a eea2e812 64fef97c 4...</td>\n    </tr>\n    <tr>\n      <th>139253</th>\n      <td>fffc63ff750064</td>\n      <td>5015c300 411b85d9 8238198c f4781d1d b5532930 e...</td>\n    </tr>\n    <tr>\n      <th>139254</th>\n      <td>fffcd063cda949</td>\n      <td>7e6266ad d8281fc5 d4ffcaef 3e0e4a47 21387fc8 c...</td>\n    </tr>\n    <tr>\n      <th>139255</th>\n      <td>fffe1d764579d5</td>\n      <td>1a63248d 9c3b96a5 1398a873 4e2d4c2d f71c538e 8...</td>\n    </tr>\n  </tbody>\n</table>\n<p>139256 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_orders = pd.read_csv('train_orders.csv')\n",
    "train_ancestors = pd.read_csv('train_ancestors.csv')\n",
    "train_orders"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1862f0a6': 'code', '2a9e43d6': 'code', '038b763d': 'code', '2eefe0ef': 'code', '0beab1cd': 'code', '9a78ab76': 'code', 'ebe125d5': 'code', 'd9dced8b': 'code', '86497fe1': 'code', 'e2c8e725': 'code', 'ff7c44ed': 'code', '0e7c906e': 'code', 'dd0c804a': 'code', '781bbf3c': 'code', 'bd94f005': 'code', '62638fba': 'code', 'bb69e88c': 'code', '6b5664c7': 'code', '23783525': 'code', '8522781a': 'code', '8ca8392c': 'code', '17ec3fc4': 'code', '76512d50': 'code', 'a98c5d9f': 'code', '06365725': 'code', '59959af5': 'code', '80151ab7': 'code', '5bf9ca51': 'code', 'f5504853': 'code', '9f50dca0': 'code', '21616367': 'markdown', 'fcb6792d': 'markdown', '63c26fa2': 'markdown', '4bb2e30a': 'markdown', 'a6357f7e': 'markdown', '45082c89': 'markdown', '77e56113': 'markdown', '448eb224': 'markdown', '032e2820': 'markdown', '8554b284': 'markdown', '36002912': 'markdown', 'ac301a84': 'markdown', '23705731': 'markdown', '1496beaf': 'markdown', '2e1a5949': 'markdown', '7e2f170a': 'markdown', 'bfbde93e': 'markdown', '0d136e08': 'markdown', '915643b3': 'markdown', '8ffe0b25': 'markdown', '8a4c95d1': 'markdown', 'b69a4f9b': 'markdown', 'c3ce0945': 'markdown', '3eebeb87': 'markdown', '1ae087ab': 'markdown', 'aaad8355': 'markdown', '503926eb': 'markdown', '3e5f860d': 'markdown'}\n"
     ]
    }
   ],
   "source": [
    "with open('train/00001756c60be8.json') as f:\n",
    "    templates = json.load(f)\n",
    "\n",
    "print(templates['cell_type'])\n",
    "cell_type = templates['cell_type']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "['21616367',\n 'fcb6792d',\n '63c26fa2',\n '4bb2e30a',\n 'a6357f7e',\n '45082c89',\n '77e56113',\n '448eb224',\n '032e2820',\n '8554b284',\n '36002912',\n 'ac301a84',\n '23705731',\n '1496beaf',\n '2e1a5949',\n '7e2f170a',\n 'bfbde93e',\n '0d136e08',\n '915643b3',\n '8ffe0b25',\n '8a4c95d1',\n 'b69a4f9b',\n 'c3ce0945',\n '3eebeb87',\n '1ae087ab',\n 'aaad8355',\n '503926eb',\n '3e5f860d']"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markdown = list()\n",
    "for i in cell_type.keys():\n",
    "    if cell_type[i] == 'markdown':\n",
    "        markdown.append(i)\n",
    "markdown"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# This Python 3 environment comes with many helpful analytics libraries installed\n",
      "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
      "# For example, here's several helpful packages to load\n",
      "\n",
      "import numpy as np # linear algebra\n",
      "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
      "\n",
      "# Input data files are available in the read-only \"../input/\" directory\n",
      "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
      "\n",
      "import os\n",
      "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
      "    for filename in filenames:\n",
      "        print(os.path.join(dirname, filename))\n",
      "\n",
      "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
      "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
      "-------------------\n",
      "**Импортируем необходимые для работы функции и классы**\n",
      "-------------------\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import random\n",
      "\n",
      "from sklearn.model_selection import train_test_split, cross_val_score\n",
      "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
      "from catboost import CatBoostRegressor\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.metrics import r2_score as r2\n",
      "from sklearn.model_selection import KFold, GridSearchCV\n",
      "\n",
      "from datetime import datetime\n",
      "\n",
      "import matplotlib\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "%matplotlib inline\n",
      "-------------------\n",
      "**Подключаем предупреждения**\n",
      "-------------------\n",
      "import warnings\n",
      "warnings.filterwarnings('ignore')\n",
      "-------------------\n",
      "**Устанавливаем значения, чтобы везде был одинаковый шрифт и размер**\n",
      "-------------------\n",
      "matplotlib.rcParams.update({'font.size': 14})\n",
      "-------------------\n",
      "**Задаем функцию для подсчета метрик**\n",
      "-------------------\n",
      "def evaluate_preds(train_true_values, train_pred_values, test_true_values, test_pred_values):\n",
      "    print(\"Train R2:\\t\" + str(round(r2(train_true_values, train_pred_values), 3)))\n",
      "    print(\"Test R2:\\t\" + str(round(r2(test_true_values, test_pred_values), 3)))\n",
      "    \n",
      "    plt.figure(figsize=(18,10))\n",
      "    \n",
      "    plt.subplot(121)\n",
      "    sns.scatterplot(x=train_pred_values, y=train_true_values)\n",
      "    plt.xlabel('Predicted values')\n",
      "    plt.ylabel('True values')\n",
      "    plt.title('Train sample prediction')\n",
      "    \n",
      "    plt.subplot(122)\n",
      "    sns.scatterplot(x=test_pred_values, y=test_true_values)\n",
      "    plt.xlabel('Predicted values')\n",
      "    plt.ylabel('True values')\n",
      "    plt.title('Test sample prediction')\n",
      "\n",
      "    plt.show()\n",
      "-------------------\n",
      "**Указываем путь к файлам с данными**\n",
      "-------------------\n",
      "TRAIN_DATASET_PATH = '/kaggle/input/real-estate-price-prediction-moscow/train.csv'\n",
      "TEST_DATASET_PATH = '/kaggle/input/real-estate-price-prediction-moscow/test.csv'\n",
      "-------------------\n",
      "**Загрузка данных**\n",
      "-------------------\n",
      "-------------------\n",
      "*Описание датасета*\n",
      "\n",
      "**Id** - идентификационный номер квартиры\n",
      "\n",
      "**DistrictId** - идентификационный номер района\n",
      "\n",
      "**Rooms** - количество комнат\n",
      "\n",
      "**Square** - площадь\n",
      "\n",
      "**LifeSquare** - жилая площадь\n",
      "\n",
      "**KitchenSquare** - площадь кухни\n",
      "\n",
      "**Floor** - этаж\n",
      "\n",
      "**HouseFloor** - количество этажей в доме\n",
      "\n",
      "**HouseYear** - год постройки дома\n",
      "\n",
      "**Ecology_1, Ecology_2, Ecology_3** - экологические показатели местности\n",
      "\n",
      "**Social_1, Social_2, Social_3** - социальные показатели местности\n",
      "\n",
      "**Healthcare_1, Helthcare_2** - показатели местности, связанные с охраной здоровья\n",
      "\n",
      "**Shops_1, Shops_2** - показатели, связанные с наличием магазинов, торговых центров\n",
      "\n",
      "**Price** - цена квартиры\n",
      "-------------------\n",
      "-------------------\n",
      "**Считываем обучающий набор данных**\n",
      "-------------------\n",
      "train_df = pd.read_csv(TRAIN_DATASET_PATH)\n",
      "train_df.tail()\n",
      "-------------------\n",
      "*Тип данных обучающего сета*\n",
      "-------------------\n",
      "train_df.dtypes\n",
      "-------------------\n",
      "*Деление признаков на числовые и текстовые*\n",
      "-------------------\n",
      "num_feat = list(train_df.select_dtypes(exclude='object').columns)\n",
      "obj_feat = list(train_df.select_dtypes(include='object').columns)\n",
      "target = 'Price'\n",
      "\n",
      "num_feat\n",
      "-------------------\n",
      "**Считываем тестовый набор данных**\n",
      "-------------------\n",
      "test_df = pd.read_csv(TEST_DATASET_PATH)\n",
      "test_df.tail()\n",
      "-------------------\n",
      "*Выводим сколько строк в тесте и на трейне*\n",
      "-------------------\n",
      "print('Строк в трейне:', train_df.shape[0])\n",
      "print('Строк в тесте', test_df.shape[0])\n",
      "-------------------\n",
      "*На обучении на один признак больше, чем на тесте*\n",
      "-------------------\n",
      "train_df.shape[1] - 1 == test_df.shape[1]\n",
      "submission_df = pd.read_csv('/kaggle/input/real-estate-price-prediction-moscow/sample_submission.csv')\n",
      "-------------------\n",
      "**Приведение типов**\n",
      "-------------------\n",
      "train_df['Id'] = train_df['Id'].astype(str)\n",
      "-------------------\n",
      "**Поиск признаков с выбросами**\n",
      "-------------------\n",
      "train_df[num_feat].hist(\n",
      "    figsize=(16,16)\n",
      ")\n",
      "plt.show()\n",
      "-------------------\n",
      "Выбросы наблюдаются в: HouseYear, KitchenSquare.\n",
      "\n",
      "Признаки с аномально высоким значением, которые нужно будет ограничить: HouseFloor, LifeSquare, Rooms, Square.\n",
      "-------------------\n",
      "train_df.describe().T\n",
      "-------------------\n",
      "Признаки Rooms, KitchenSquare, HouseFloor имеют в некоторых наблюдениях нулевые значения\n",
      "-------------------\n",
      "grid = sns.jointplot(train_df['Rooms'], train_df['Price'], kind='reg')\n",
      "grid.fig.set_figwidth(8)\n",
      "grid.fig.set_figheight(8)\n",
      "grid = sns.jointplot(train_df['KitchenSquare'], train_df['Price'], kind='reg')\n",
      "grid.fig.set_figwidth(8)\n",
      "grid.fig.set_figheight(8)\n",
      "-------------------\n",
      "Значения меньше 1 и больше 250 отсекаем\n",
      "-------------------\n",
      "train_df_temp = train_df.loc[train_df['KitchenSquare']<250]\n",
      "grid = sns.jointplot(train_df_temp['KitchenSquare'], train_df_temp['Price'], kind='reg')\n",
      "grid.fig.set_figwidth(8)\n",
      "grid.fig.set_figheight(8)\n",
      "-------------------\n",
      "За выброс посчитаем значения менее 3 кв.м. и больше 30 кв.м.\n",
      "-------------------\n",
      "-------------------\n",
      "**График распределения целевой переменной - цены**\n",
      "-------------------\n",
      "plt.figure(figsize = (16, 8))\n",
      "\n",
      "train_df['Price'].hist(bins=30)\n",
      "plt.ylabel('Count')\n",
      "plt.xlabel('Price')\n",
      "\n",
      "plt.title('Target distribution')\n",
      "plt.show()\n",
      "-------------------\n",
      "Корреляция\n",
      "-------------------\n",
      "correlation = train_df.corrwith(train_df['Price']).sort_values(ascending=False)\n",
      "correlation.drop('Price', inplace=True)\n",
      "\n",
      "plt.figure(figsize = (16, 8))\n",
      "plt.bar(correlation.index, correlation)\n",
      "plt.xticks(rotation='90')\n",
      "plt.xlabel('Features', fontsize=15)\n",
      "plt.ylabel('Correlation', fontsize=15)\n",
      "plt.title('Feature correlation', fontsize=15)\n",
      "plt.show()\n",
      "-------------------\n",
      "Создания класса подготовки данных\n",
      "-------------------\n",
      "class Data:\n",
      "    \n",
      "    def __init__(self):\n",
      "        \"\"\"Константы для обработки выбросов на основе анализа данных\"\"\"\n",
      "        self.Square_min = 15\n",
      "        self.Square_max = 300\n",
      "        \n",
      "        self.LifeSquare_min = 10\n",
      "        self.LifeSquare_max = 280\n",
      "        \n",
      "        self.Rooms_min = 1\n",
      "        self.Rooms_max = 5\n",
      "        \n",
      "        self.HouseFloor_min = 1\n",
      "        self.HouseFloor_max = 50\n",
      "        \n",
      "        self.KitchenSquare_min = 3\n",
      "        self.KitchenSquare_max = 30\n",
      "        \n",
      "        self.current_year = datetime.now().year\n",
      "        \n",
      "        self.medians = None\n",
      "        self.DistrictId_value_counts = None\n",
      "        self.SquareMeterPrice_by_DistrictId = None\n",
      "        self.Healthcare_1_by_DistrictId = None\n",
      "        \n",
      "        \n",
      "    def fit(self, train_df):\n",
      "        \n",
      "        # медианные значения\n",
      "        self.medians = train_df[['LifeSquare', 'HouseFloor']].median()\n",
      "        \n",
      "        # подсчет популярных районов\n",
      "        self.DistrictId_value_counts = dict(train_df['DistrictId'].value_counts())\n",
      "        \n",
      "        # подсчет средней цены за м2 по району\n",
      "        train_df_temp = train_df.loc[((train_df['Square'] > self.Square_min) & (train_df['Square'] < self.Square_max))]\n",
      "        train_df_temp[\"SquareMeterPrice\"] = train_df_temp[\"Price\"] / train_df_temp[\"Square\"]\n",
      "        self.SquareMeterPrice_by_DistrictId = train_df_temp.groupby('DistrictId', as_index=False)\\\n",
      "            .agg({'SquareMeterPrice': 'mean'})\\\n",
      "            .rename(columns={'SquareMeterPrice': 'AverageSquareMeterPrice'})\n",
      "        \n",
      "        # подсчет среднего значения признака Healthcare_1 по району\n",
      "        self.Healthcare_1_by_DistrictId = train_df.groupby('DistrictId', as_index=False)\\\n",
      "            .agg({'Healthcare_1': 'mean'})\\\n",
      "            .rename(columns={'Healthcare_1': 'AverageHealthcare_1'})\n",
      "        \n",
      "        del train_df_temp\n",
      "        \n",
      "    def transform(self, train_df):\n",
      "        \n",
      "        # Обработка пропусков\n",
      "        train_df[['LifeSquare', 'HouseFloor']] = train_df[['LifeSquare', 'HouseFloor']].fillna(self.medians)\n",
      "        \n",
      "        # Обработка выбросов\n",
      "        \n",
      "        # площадь\n",
      "        train_df.loc[(train_df['Square'] > self.Square_max), 'Square'] = self.Square_max\n",
      "        train_df.loc[(train_df['Square'] < self.Square_min), 'Square'] = self.Square_min\n",
      "        \n",
      "        # жилая площадь\n",
      "        train_df.loc[(train_df['LifeSquare'] < self.LifeSquare_min), 'LifeSquare'] = self.LifeSquare_min\n",
      "        train_df.loc[(train_df['LifeSquare'] > self.LifeSquare_max), 'LifeSquare'] = self.LifeSquare_max\n",
      "        \n",
      "        # площадь кухни\n",
      "        train_df.loc[(train_df['KitchenSquare'] < self.KitchenSquare_min), 'KitchenSquare'] = self.KitchenSquare_min\n",
      "        train_df.loc[(train_df['KitchenSquare'] > self.KitchenSquare_max), 'KitchenSquare'] = self.KitchenSquare_max\n",
      "        \n",
      "        # год постройки дома\n",
      "        train_df.loc[(train_df['HouseYear'] > self.current_year), 'HouseYear'] = self.current_year\n",
      "        \n",
      "        # количество комнат\n",
      "        train_df.loc[(train_df['Rooms'] > self.Rooms_max), 'Rooms'] = self.Rooms_max\n",
      "        train_df.loc[(train_df['Rooms'] < self.Rooms_min), 'Rooms'] = self.Rooms_min\n",
      "        \n",
      "        # количество этажей\n",
      "        train_df.loc[(train_df['HouseFloor'] < self.HouseFloor_min), 'HouseFloor'] = self.HouseFloor_min\n",
      "        train_df.loc[(train_df['HouseFloor'] > self.HouseFloor_max), 'HouseFloor'] = self.HouseFloor_max\n",
      "        \n",
      "        # если этаж больше этажности дома, то присваиваем случайный этаж от self.HouseFloor_min до максимального этажа в доме\n",
      "        floor_outliers = train_df.loc[train_df['Floor'] > train_df['HouseFloor']].index\n",
      "        train_df.loc[floor_outliers, 'Floor'] = train_df.loc[floor_outliers, 'HouseFloor'].apply(lambda x: self.HouseFloor_min if (self.HouseFloor_min == x) else np.random.randint(self.HouseFloor_min, x))\n",
      "        \n",
      "        # Обработка категорий\n",
      "        train_df = pd.concat([train_df, pd.get_dummies(train_df['Ecology_2'], prefix='Ecology_2', dtype='int8')], axis=1)\n",
      "        train_df = pd.concat([train_df, pd.get_dummies(train_df['Ecology_3'], prefix='Ecology_3', dtype='int8')], axis=1)\n",
      "        train_df = pd.concat([train_df, pd.get_dummies(train_df['Shops_2'], prefix='Shops_2', dtype='int8')], axis=1)\n",
      "        \n",
      "        return train_df\n",
      "    \n",
      "    def features(self, train_df):\n",
      "        \n",
      "        # добавление признака популярности района\n",
      "        train_df['DistrictId_counts'] = train_df['DistrictId'].map(self.DistrictId_value_counts)\n",
      "        train_df['DistrictId_counts'].fillna(train_df['DistrictId_counts'].median(), inplace=True)\n",
      "        \n",
      "        # добавление признака средней стоимости м2 по району\n",
      "        train_df = train_df.merge(self.SquareMeterPrice_by_DistrictId, on=[\"DistrictId\"], how='left')\n",
      "        train_df['AverageSquareMeterPrice'].fillna(train_df['AverageSquareMeterPrice'].median(), inplace=True)\n",
      "        \n",
      "        # добавление признака среднего значения Healthcare_1 по району\n",
      "        train_df = train_df.merge(self.Healthcare_1_by_DistrictId, on=[\"DistrictId\"], how='left')\n",
      "        train_df['AverageHealthcare_1'].fillna(train_df['AverageHealthcare_1'].median(), inplace=True)\n",
      "        \n",
      "        return train_df\n",
      "-------------------\n",
      "Инициализация класса Data\n",
      "-------------------\n",
      "data_inst = Data()\n",
      "\n",
      "# тренировочные данные\n",
      "data_inst.fit(train_df)\n",
      "train_df = data_inst.transform(train_df)\n",
      "train_df = data_inst.features(train_df)\n",
      "\n",
      "# валидационные данные\n",
      "test_df = data_inst.transform(test_df)\n",
      "test_df = data_inst.features(test_df)\n",
      "-------------------\n",
      "Создаем список признаков, используемых в модели - отбор признаков\n",
      "-------------------\n",
      "feature_names = ['AverageSquareMeterPrice', 'DistrictId_counts', 'Rooms', 'Square', 'LifeSquare', 'KitchenSquare', 'Floor',\n",
      "                    'HouseFloor', 'HouseYear', 'Helthcare_2', 'Ecology_1', 'Social_1', 'Social_2', 'Social_3',\n",
      "                    'Shops_1', 'Ecology_2_A', 'Ecology_2_B', 'Ecology_3_A', 'Ecology_3_B', 'Shops_2_A', 'Shops_2_B',\n",
      "                    'AverageHealthcare_1']\n",
      "target_name = 'Price'\n",
      "train_df = train_df[feature_names + [target_name]]\n",
      "test_df = test_df[feature_names + ['Id']]\n",
      "X = train_df[feature_names]\n",
      "y = train_df[target_name]\n",
      "-------------------\n",
      "**Обучение модели на CatBoostRegressor**\n",
      "\n",
      "Вычисления гиперпараметров модели при помощи randomized_search() learning_rate=0.1 iterations=1150 depth=8\n",
      "-------------------\n",
      "final_model = CatBoostRegressor(\n",
      "    silent=True,\n",
      "    learning_rate=0.1,\n",
      "    iterations=1150,\n",
      "    eval_metric='R2',\n",
      "    depth=8\n",
      ")\n",
      "\n",
      "final_model.fit(X, y)\n",
      "\n",
      "cv_score = cross_val_score(\n",
      "    final_model,\n",
      "    X,\n",
      "    y,\n",
      "    scoring='r2',\n",
      "    cv=KFold(\n",
      "            n_splits=5,\n",
      "            shuffle=True,\n",
      "            random_state=42\n",
      "    )\n",
      ")\n",
      "-------------------\n",
      "Оценка модели\n",
      "-------------------\n",
      "print(f'R2: {round(cv_score.mean(), 3)}')\n",
      "-------------------\n",
      "**Сортировка признаков по важности**\n",
      "-------------------\n",
      "feature_importances = pd.DataFrame(\n",
      "    zip(X.columns, final_model.get_feature_importance()),\n",
      "    columns=['feature_name', 'importance']\n",
      ")\n",
      "\n",
      "feature_importances.sort_values(by='importance', ascending=False, inplace=True)\n",
      "feature_importances.head(20)\n",
      "-------------------\n",
      "**Создание датафрейма с предсказаниями**\n",
      "-------------------\n",
      "preds_final = pd.DataFrame()\n",
      "preds_final['Id'] = test_df['Id'].copy()\n",
      "\n",
      "test_df.set_index('Id', inplace=True)\n",
      "test_df = test_df[feature_names]\n",
      "y_pred_final = final_model.predict(test_df)\n",
      "\n",
      "submission_df['Price'] = y_pred_final\n",
      "submission_df.to_csv('./predictions.csv', index=False, encoding='utf-8', sep=',')\n",
      "\n",
      "submission_df.head()\n"
     ]
    }
   ],
   "source": [
    "for i in order_i:\n",
    "    if cell_type[i] == 'markdown':\n",
    "        print('-------------------')\n",
    "        print(templates['source'][i])\n",
    "        print('-------------------')\n",
    "    else:\n",
    "        print(templates['source'][i])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "from translate import Translator\n",
    "translator = Translator(from_lang='russian', to_lang='english')\n",
    "translation = translator.translate('hello')\n",
    "print(translation)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "generator raised StopIteration",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mStopIteration\u001B[0m                             Traceback (most recent call last)",
      "File \u001B[0;32m~/anaconda3/lib/python3.9/site-packages/translate/translate.py:45\u001B[0m, in \u001B[0;36m<genexpr>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     44\u001B[0m text_list \u001B[38;5;241m=\u001B[39m wrap(text, TRANSLATION_API_MAX_LENGHT, replace_whitespace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m---> 45\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprovider\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_translation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext_wraped\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m text_wraped \u001B[38;5;129;01min\u001B[39;00m text_list)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.9/site-packages/translate/providers/mymemory_translated.py:49\u001B[0m, in \u001B[0;36mMyMemoryProvider.get_translation\u001B[0;34m(self, text)\u001B[0m\n\u001B[1;32m     48\u001B[0m matches \u001B[38;5;241m=\u001B[39m data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmatches\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m---> 49\u001B[0m next_best_match \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mmatch\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mmatch\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mmatches\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m next_best_match[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtranslation\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "\u001B[0;31mStopIteration\u001B[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[0;32mIn [101]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      4\u001B[0m     lst \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m()\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m tkns:\n\u001B[0;32m----> 6\u001B[0m         lst\u001B[38;5;241m.\u001B[39mappend(\u001B[43mtranslator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtranslate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mj\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m      7\u001B[0m     tokens\u001B[38;5;241m.\u001B[39mappend(lst)\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28mprint\u001B[39m(tokens)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.9/site-packages/translate/translate.py:45\u001B[0m, in \u001B[0;36mTranslator.translate\u001B[0;34m(self, text)\u001B[0m\n\u001B[1;32m     42\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m text\n\u001B[1;32m     44\u001B[0m text_list \u001B[38;5;241m=\u001B[39m wrap(text, TRANSLATION_API_MAX_LENGHT, replace_whitespace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m---> 45\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m \u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprovider\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_translation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext_wraped\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtext_wraped\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtext_list\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: generator raised StopIteration"
     ]
    }
   ],
   "source": [
    "tokens = list()\n",
    "for i in markdown:\n",
    "    tkns = nltk.word_tokenize(templates['source'][i])\n",
    "    lst = list()\n",
    "    for j in tkns:\n",
    "        lst.append(translator.translate(j))\n",
    "    tokens.append(lst)\n",
    "print(tokens)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}